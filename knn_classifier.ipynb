{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNht3r3c9wv7WE/hkGP3KtL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisli36/Homework-Classification/blob/main/knn_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "dz2-Dl2TJZMW",
        "outputId": "c7bb02d6-b8c1-40e0-f82c-270fba7c0c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] -d DATASET [-k NEIGHBORS] [-j JOBS]\n",
            "colab_kernel_launcher.py: error: the following arguments are required: -d/--dataset\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "# import the necessary packages\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def image_to_feature_vector(image, size=(32, 32)):\n",
        "\t# resize the image to a fixed size, then flatten the image into\n",
        "\t# a list of raw pixel intensities\n",
        "\treturn cv2.resize(image, size).flatten()\n",
        "\n",
        "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
        "\t# extract a 3D color histogram from the HSV color space using\n",
        "\t# the supplied number of `bins` per channel\n",
        "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
        "\t\t[0, 180, 0, 256, 0, 256])\n",
        "\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n",
        "\tif imutils.is_cv2():\n",
        "\t\thist = cv2.normalize(hist)\n",
        "\t# otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
        "\t# personally hate the way this is done\n",
        "\telse:\n",
        "\t\tcv2.normalize(hist, hist)\n",
        "\t# return the flattened histogram as the feature vector\n",
        "\treturn hist.flatten()\n",
        "\n",
        "# construct the argument parse and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
        "\thelp=\"path to input dataset\")\n",
        "ap.add_argument(\"-k\", \"--neighbors\", type=int, default=1,\n",
        "\thelp=\"# of nearest neighbors for classification\")\n",
        "ap.add_argument(\"-j\", \"--jobs\", type=int, default=-1,\n",
        "\thelp=\"# of jobs for k-NN distance (-1 uses all available cores)\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "# grab the list of images that we'll be describing\n",
        "print(\"[INFO] describing images...\")\n",
        "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
        "# initialize the raw pixel intensities matrix, the features matrix,\n",
        "# and labels list\n",
        "rawImages = []\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "# loop over the input images\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "\t# load the image and extract the class label (assuming that our\n",
        "\t# path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
        "\timage = cv2.imread(imagePath)\n",
        "\tlabel = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
        "\t# extract raw pixel intensity \"features\", followed by a color\n",
        "\t# histogram to characterize the color distribution of the pixels\n",
        "\t# in the image\n",
        "\tpixels = image_to_feature_vector(image)\n",
        "\thist = extract_color_histogram(image)\n",
        "\t# update the raw images, features, and labels matricies,\n",
        "\t# respectively\n",
        "\trawImages.append(pixels)\n",
        "\tfeatures.append(hist)\n",
        "\tlabels.append(label)\n",
        "\t# show an update every 100 images\n",
        "\tif i > 0 and i % 100 == 0:\n",
        "\t\tprint(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))\n",
        "\n",
        "# show some information on the memory consumed by the raw images\n",
        "# matrix and features matrix\n",
        "rawImages = np.array(rawImages)\n",
        "features = np.array(features)\n",
        "labels = np.array(labels)\n",
        "print(\"[INFO] pixels matrix: {:.2f}MB\".format(\n",
        "\trawImages.nbytes / (1024 * 1000.0)))\n",
        "print(\"[INFO] features matrix: {:.2f}MB\".format(\n",
        "\tfeatures.nbytes / (1024 * 1000.0)))\n",
        "\n",
        "# partition the data into training and testing splits, using 75%\n",
        "# of the data for training and the remaining 25% for testing\n",
        "(trainRI, testRI, trainRL, testRL) = train_test_split(\n",
        "\trawImages, labels, test_size=0.25, random_state=42)\n",
        "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
        "\tfeatures, labels, test_size=0.25, random_state=42)\n",
        "\n",
        "# train and evaluate a k-NN classifer on the raw pixel intensities\n",
        "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
        "model = KNeighborsClassifier(n_neighbors=args[\"neighbors\"],\n",
        "\tn_jobs=args[\"jobs\"])\n",
        "model.fit(trainRI, trainRL)\n",
        "acc = model.score(testRI, testRL)\n",
        "print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc * 100))\n",
        "\n",
        "# train and evaluate a k-NN classifer on the histogram\n",
        "# representations\n",
        "print(\"[INFO] evaluating histogram accuracy...\")\n",
        "model = KNeighborsClassifier(n_neighbors=args[\"neighbors\"],\n",
        "\tn_jobs=args[\"jobs\"])\n",
        "model.fit(trainFeat, trainLabels)\n",
        "acc = model.score(testFeat, testLabels)\n",
        "print(\"[INFO] histogram accuracy: {:.2f}%\".format(acc * 100))"
      ]
    }
  ]
}